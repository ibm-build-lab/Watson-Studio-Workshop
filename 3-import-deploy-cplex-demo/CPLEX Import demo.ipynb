{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying a CPLEX export file with MIP starts with Watson Machine Learning\n",
    "\n",
    "This notebook shows you how to deploy a CPLEX export file with MIP starts, create and monitor jobs, and get solution and logs using the Watson Machine Learning Python Client.\n",
    "\n",
    "This notebook runs on Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Install the Watson Machine Learning client API](#setup)\n",
    "2. [Create a client instance](#create)\n",
    "3. [Prepare your model archive](#prepare)\n",
    "4. [Upload your model on Watson Machine Learning](#upload)\n",
    "5. [Create a deployment](#deploy)\n",
    "6. [Create and monitor a job with inline data for your deployed model](#job)\n",
    "7. [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "### Set up the Watson Machine Learning client\n",
    "\n",
    "Before you use the sample code in this notebook, you must:\n",
    "\n",
    "- create a <a href=\"https://cloud.ibm.com/catalog/services/machine-learning\" target=\"_blank\" rel=\"noopener noreferrer\">Watson Machine Learning (WML) Service</a> instance. A free plan is offered and information about how to create the instance can be found at <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-setup.html\" target=\"_blank\" rel=\"noopener noreferrer\"> https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/wml-setup.html.</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install and then import the Watson Machine Learning client library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ibm-watson-machine-learning in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (1.0.308)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-watson-machine-learning) (21.3)\n",
      "Requirement already satisfied: pandas<1.6.0,>=0.24.2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-watson-machine-learning) (1.4.3)\n",
      "Requirement already satisfied: certifi in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-watson-machine-learning) (2023.5.7)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-watson-machine-learning) (2.29.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-watson-machine-learning) (4.11.3)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-watson-machine-learning) (1.26.11)\n",
      "Requirement already satisfied: ibm-cos-sdk<2.14.0,>=2.12.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-watson-machine-learning) (2.12.0)\n",
      "Requirement already satisfied: lomond in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-watson-machine-learning) (0.3.3)\n",
      "Requirement already satisfied: tabulate in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-watson-machine-learning) (0.8.10)\n",
      "Requirement already satisfied: ibm-cos-sdk-core==2.12.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watson-machine-learning) (2.12.0)\n",
      "Requirement already satisfied: ibm-cos-sdk-s3transfer==2.12.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watson-machine-learning) (2.12.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.10.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watson-machine-learning) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from ibm-cos-sdk-core==2.12.0->ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watson-machine-learning) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from pandas<1.6.0,>=0.24.2->ibm-watson-machine-learning) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from pandas<1.6.0,>=0.24.2->ibm-watson-machine-learning) (1.23.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests->ibm-watson-machine-learning) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from requests->ibm-watson-machine-learning) (3.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from importlib-metadata->ibm-watson-machine-learning) (3.8.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from lomond->ibm-watson-machine-learning) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/Python-3.10/lib/python3.10/site-packages (from packaging->ibm-watson-machine-learning) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "# Install WML client API\n",
    "\n",
    "!pip install ibm-watson-machine-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning import APIClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='create'></a>\n",
    "### Create a client instance\n",
    "\n",
    "Use your Watson Machine Learning credentials. You can find information on how to get your API key and instance's URL <a href=\"https://dataplatform.cloud.ibm.com/docs/content/DO/WML_Deployment/DeployModelRest.html?audience=wdp\">here</a> in the second step of the \"Before you begin\" section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a client using credentials\n",
    "wml_credentials = {\n",
    "      \"apikey\": \"<API>\",\n",
    "      \"url\": \"https://us-south.ml.cloud.ibm.com\"\n",
    "}\n",
    "\n",
    "client = APIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.308'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prepare'></a>\n",
    "### Prepare your model archive\n",
    "\n",
    "Use the `write_file` command to write these models to a `burger.lp` and `burger.mst` file. \n",
    "\n",
    "Use the `tar` command to create a tar archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘model’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "%mkdir model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting burger.lp\n"
     ]
    }
   ],
   "source": [
    "%%writefile burger.lp\n",
    "\n",
    "\\Problem name: good_burger\n",
    "\n",
    "Maximize\n",
    " obj: 0.250000000000 how_many_beef + 0.150000000000 how_many_bun\n",
    "      + 0.100000000000 how_many_cheese + 0.090000000000 how_many_onions\n",
    "      + 0.030000000000 how_many_pickles + 0.040000000000 how_many_lettuce\n",
    "      + 0.020000000000 how_many_ketchup + 0.040000000000 how_many_tomato\n",
    "Subject To\n",
    " c1: how_many_beef <= 5\n",
    " c2: how_many_beef >= 1\n",
    " c3: how_many_bun <= 5\n",
    " c4: how_many_bun >= 1\n",
    " c5: how_many_cheese <= 5\n",
    " c6: how_many_cheese >= 1\n",
    " c7: how_many_onions <= 5\n",
    " c8: how_many_onions >= 1\n",
    " c9: how_many_pickles <= 5\n",
    " c10: how_many_pickles >= 1\n",
    " c11: how_many_lettuce <= 5\n",
    " c12: how_many_lettuce >= 1\n",
    " c13: how_many_ketchup <= 5\n",
    " c14: how_many_ketchup >= 1\n",
    " c15: how_many_tomato <= 5\n",
    " c16: how_many_tomato >= 1\n",
    " c17: 50 how_many_beef + 330 how_many_bun + 310 how_many_cheese\n",
    "      + how_many_onions + 260 how_many_pickles + 3 how_many_lettuce\n",
    "      + 160 how_many_ketchup + 3 how_many_tomato <= 2999\n",
    " c18: 17 how_many_beef + 9 how_many_bun + 6 how_many_cheese + 2 how_many_onions\n",
    "       <= 149\n",
    " c19: 220 how_many_beef + 260 how_many_bun + 70 how_many_cheese\n",
    "      + 10 how_many_onions + 5 how_many_pickles + 4 how_many_lettuce\n",
    "      + 20 how_many_ketchup + 9 how_many_tomato <= 2999\n",
    " c20: how_many_ketchup - how_many_lettuce = 0\n",
    " c21: how_many_pickles - how_many_tomato = 0\n",
    "\n",
    "Bounds\n",
    "\n",
    "Generals\n",
    " how_many_beef how_many_bun how_many_cheese how_many_onions how_many_pickles\n",
    " how_many_lettuce how_many_ketchup how_many_tomato\n",
    "End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partial MIP starts for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting burger.mst\n"
     ]
    }
   ],
   "source": [
    "%%writefile burger.mst\n",
    "\n",
    "<CPLEXSolution version=\"1.0\">\n",
    " <header problemName=\"good_burger\"/>\n",
    " <variables>\n",
    "  <variable name=\"how_many_beef\" index=\"0\" value=\"5\"/>\n",
    "  <variable name=\"how_many_bun\" index=\"1\" value=\"5\"/>\n",
    "  <variable name=\"how_many_cheese\" index=\"2\" value=\"1\"/>\n",
    "  <variable name=\"how_many_onions\" index=\"3\" value=\"5\"/>\n",
    " </variables>\n",
    "</CPLEXSolution>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tarfile\n",
    "def reset(tarinfo):\n",
    "    tarinfo.uid = tarinfo.gid = 0\n",
    "    tarinfo.uname = tarinfo.gname = \"root\"\n",
    "    return tarinfo\n",
    "tar = tarfile.open(\"model.tar.gz\", \"w:gz\")\n",
    "tar.add(\"burger.lp\", arcname=\"burger.lp\", filter=reset)\n",
    "tar.add(\"burger.mst\", arcname=\"burger.mst\", filter=reset)\n",
    "tar.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='upload'></a>\n",
    "### Upload your model on Watson Machine Learning\n",
    "\n",
    "Store model in Watson Machine Learning with:\n",
    "* the tar archive previously created,\n",
    "* metadata including the model type and runtime\n",
    "\n",
    "Get the `model_uid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the space ID\n",
    "\n",
    "space_name = \"<Space NAME>\"\n",
    "\n",
    "space_id = [x['metadata']['id'] for x in client.spaces.get_details()['resources'] if x['entity']['name'] == space_name][0]\n",
    "\n",
    "client.set.default_space(space_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_metadata = {\n",
    "    client.repository.ModelMetaNames.NAME: \"BurgerProduction\",\n",
    "    client.repository.ModelMetaNames.DESCRIPTION: \"Model for Burger Production\",\n",
    "    client.repository.ModelMetaNames.TYPE: \"do-cplex_22.1\",\n",
    "    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: client.software_specifications.get_uid_by_name(\"do_22.1\"),\n",
    "}\n",
    "\n",
    "model_details = client.repository.store_model(model='model.tar.gz', meta_props=mnist_metadata)\n",
    "#model='/home/wsuser/work/model.tar.gz', \n",
    "model_uid = client.repository.get_model_id(model_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='deploy'></a>\n",
    "### Create a deployment \n",
    "\n",
    "Create a batch deployment for the model, providing information such as:\n",
    "* the maximum number of compute nodes\n",
    "* the T-shirt size of the compute nodes\n",
    "\n",
    "Get the `deployment_uid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "Synchronous deployment creation for uid: 'f43e5f1a-91a1-4d6d-8603-942f89969874' started\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "\n",
      "ready.\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n",
      "Successfully finished deployment creation, deployment_uid='efe2925b-9099-4e64-8ff7-3862d11debf1'\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "meta_props = {\n",
    "    client.deployments.ConfigurationMetaNames.NAME: \"BurgerProduction Deployment\",\n",
    "    client.deployments.ConfigurationMetaNames.DESCRIPTION: \"BurgerProduction Deployment\",\n",
    "    client.deployments.ConfigurationMetaNames.BATCH: {},\n",
    "    client.deployments.ConfigurationMetaNames.HARDWARE_SPEC: {'name': 'S', 'num_nodes': 1}\n",
    "}\n",
    "\n",
    "deployment_details = client.deployments.create(model_uid, meta_props=meta_props)\n",
    "\n",
    "deployment_uid = client.deployments.get_uid(deployment_details)\n",
    "\n",
    "# print deployment id if needed\n",
    "# print( deployment_uid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------  ---------------------------  -----  ------------------------  -------------  ----------  ----------------\n",
      "GUID                                  NAME                         STATE  CREATED                   ARTIFACT_TYPE  SPEC_STATE  SPEC_REPLACEMENT\n",
      "efe2925b-9099-4e64-8ff7-3862d11debf1  BurgerProduction Deployment  ready  2023-06-27T14:31:39.919Z  model          supported\n",
      "------------------------------------  ---------------------------  -----  ------------------------  -------------  ----------  ----------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GUID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>STATE</th>\n",
       "      <th>CREATED</th>\n",
       "      <th>ARTIFACT_TYPE</th>\n",
       "      <th>SPEC_STATE</th>\n",
       "      <th>SPEC_REPLACEMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>efe2925b-9099-4e64-8ff7-3862d11debf1</td>\n",
       "      <td>BurgerProduction Deployment</td>\n",
       "      <td>ready</td>\n",
       "      <td>2023-06-27T14:31:39.919Z</td>\n",
       "      <td>model</td>\n",
       "      <td>supported</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   GUID                         NAME  STATE  \\\n",
       "0  efe2925b-9099-4e64-8ff7-3862d11debf1  BurgerProduction Deployment  ready   \n",
       "\n",
       "                    CREATED ARTIFACT_TYPE SPEC_STATE SPEC_REPLACEMENT  \n",
       "0  2023-06-27T14:31:39.919Z         model  supported                   "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all existing deployments\n",
    "\n",
    "client.deployments.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='job'></a>\n",
    "### Create and monitor a job with inline data for your deployed model\n",
    "\n",
    "Create a payload containing inline input data.\n",
    "\n",
    "Create a new job with this payload and the deployment.\n",
    "\n",
    "Get the `job_uid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "solve_payload = {\n",
    "    \"solve_parameters\" : {\n",
    "                \"oaas.logAttachmentName\":\"log.txt\",\n",
    "                \"oaas.logTailEnabled\":\"true\",\n",
    "                \"oaas.resultsFormat\": \"XML\"\n",
    "            },\n",
    "    client.deployments.DecisionOptimizationMetaNames.INPUT_DATA: [\n",
    "    ],\n",
    "    client.deployments.DecisionOptimizationMetaNames.OUTPUT_DATA: [\n",
    "    {\n",
    "        \"id\":\".*\\.xml\"\n",
    "    },\n",
    "    {\n",
    "        \"id\":\"log.txt\"\n",
    "    }\n",
    "    ]\n",
    "}\n",
    "job_details = client.deployments.create_job(deployment_uid, solve_payload)\n",
    "job_uid = client.deployments.get_job_uid(job_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display job status until it is completed.\n",
    "\n",
    "The first job of a new deployment might take some time as a compute node must be started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queued...\n",
      "queued...\n",
      "queued...\n",
      "queued...\n",
      "queued...\n",
      "running...\n",
      "running...\n",
      "optimal_solution\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "while job_details['entity']['decision_optimization']['status']['state'] not in ['completed', 'failed', 'canceled']:\n",
    "    print(job_details['entity']['decision_optimization']['status']['state'] + '...')\n",
    "    sleep(5)\n",
    "    job_details=client.deployments.get_job_details(job_uid)\n",
    "\n",
    "print(job_details['entity']['decision_optimization']['solve_state']['solve_status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the MIP Starts were used by the engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIP starts were provided to the job and were used by the engine\n",
      "b'[2023-06-27T14:32:21.933Z, INFO] 1 of 1 MIP starts provided solutions.\\n'\n",
      "b\"[2023-06-27T14:32:21.936Z, INFO] MIP start 'm1' defined initial solution with objective 2.8000.\\n\"\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import io\n",
    "\n",
    "output_data = job_details['entity']['decision_optimization']['output_data']\n",
    "\n",
    "starts_in_logs = [line for o in output_data if o['id'] == 'log.txt' for line in io.BytesIO(base64.b64decode(o['content'])) if \"start\" in str(line) ]\n",
    "if len(starts_in_logs) == 0:\n",
    "    print(\"Something went wrong\")\n",
    "elif len(starts_in_logs) == 1:\n",
    "    print(\"MIP starts were provided to the job but engine rejected them\")\n",
    "    print(\"Something went wrong\")\n",
    "elif len(starts_in_logs) == 2:\n",
    "    print(\"MIP starts were provided to the job and were used by the engine\")\n",
    "    for d in starts_in_logs:\n",
    "        print(d)\n",
    "else:\n",
    "    print(\"Something went wrong\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following method to delete the deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.deployments.delete(deployment_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='summary'></a>\n",
    "### Summary and next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've successfully completed this notebook! \n",
    "\n",
    "You've learned how to:\n",
    "\n",
    "- work with the Watson Machine Learning client\n",
    "- prepare your model archive and upload your model on Watson Machine Learning\n",
    "- create a deployment\n",
    "- create and monitor a job with inline data for your deployed model\n",
    "\n",
    "Check out our online documentation at <a href=\"https://dataplatform.cloud.ibm.com/docs\" target=\"_blank\" rel=\"noopener noreferrer\">https://dataplatform.cloud.ibm.com/docs</a> for more samples, tutorials and documentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**\n",
    "In this sample, the optimization content (LP file + MIP Starts file) was uploaded as Watson Machine Learning model content (call to store_model). When the job is triggered, this model content is used: there is no need for any additional input data.\n",
    "\n",
    "Another possible implementation could be to create an empty Watson Machine Learning model (call store_model with an empty tar.gz file), then when triggering the job, pass the optimization content (LP file + MIP Starts file) as the job input data (client.deployments.DecisionOptimizationMetaNames.INPUT_DATA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Copyright © 2019, 2023. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
